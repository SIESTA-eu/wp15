{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20358221-95c7-4117-8366-ccdf517f2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "from numba import jit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbc1ab9c-c215-4ef9-a546-7541e3be3db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_pipeline(data):\n",
    "    return np.mean(data, axis=1, keepdims=True)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def loo_(data):\n",
    "    n_features, n_samples = data.shape\n",
    "    loo_means = np.zeros((n_features, n_samples))\n",
    "    loo_stds = np.zeros((n_features, n_samples))\n",
    "\n",
    "    for i in range(n_features):\n",
    "        v = data[i]\n",
    "        s, s2 = np.sum(v), np.sum(v**2)\n",
    "        means = (s - v) / (n_samples - 1)\n",
    "        #vars_ = ((s2 - v**2) - (n_samples - 1) * means**2) / (n_samples - 2)\n",
    "        #loo_means[i], loo_stds[i] = means, np.sqrt(vars_)\n",
    "        loo_means[i] = means\n",
    "        \n",
    "    return loo_means, loo_stds\n",
    "\n",
    "@jit(nopython=True)\n",
    "def gen_noise(chol_factor, sensitivity, max_attempts=10000):\n",
    "    dim = sensitivity.shape[0]\n",
    "    for _ in range(max_attempts):\n",
    "        z = np.random.standard_normal(dim)\n",
    "        noise = chol_factor @ z\n",
    "        if np.all(noise >= sensitivity):\n",
    "            return noise, True\n",
    "    return noise, False\n",
    "\n",
    "def dp(data, original_output, epsilon=1.0):\n",
    "    loo_means, loo_stds = loo_(data)\n",
    "    sensitivity = np.max(np.abs(loo_means - original_output), axis=1)\n",
    "\n",
    "    loo_scales = np.std(loo_means, axis=1) / epsilon\n",
    "    cov = np.cov(data)\n",
    "    scale_factors = 2 * loo_scales / np.sqrt(np.diag(cov))\n",
    "    scale_matrix = np.diag(scale_factors)\n",
    "\n",
    "    noise_cov = scale_matrix @ cov @ scale_matrix\n",
    "    if np.min(np.linalg.eigvals(noise_cov)) <= 1e-10:\n",
    "        noise_cov += np.eye(data.shape[0]) * 1e-8\n",
    "\n",
    "    try:\n",
    "        chol = np.linalg.cholesky(noise_cov)\n",
    "        noise, success = gen_noise(chol, sensitivity)\n",
    "        if not success:\n",
    "            raise ValueError(\"Correlated noise generation failed\")\n",
    "    except (np.linalg.LinAlgError, ValueError):\n",
    "        warnings.warn(\"Failed to generate correlated noise, using independent noise\")\n",
    "        noise = np.array([np.random.normal(0, 2 * s) for s in loo_scales])\n",
    "        for i in range(len(noise)):\n",
    "            while abs(noise[i]) < sensitivity[i]:\n",
    "                noise[i] = np.random.normal(0, 2 * loo_scales[i])\n",
    "\n",
    "    noisy_outputs = original_output.flatten() + noise\n",
    "    return noisy_outputs, sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "3d7dbd6a-09cb-49d1-965a-be7c746167e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time taken size [3,20000]: 00:00:10\n",
      "\n",
      "Total time taken size [400,50000]: 00:00:03\n"
     ]
    }
   ],
   "source": [
    "def main(data):\n",
    "    original_output = user_pipeline(data)\n",
    "    with warnings.catch_warnings(record=True) as w:\n",
    "        warnings.simplefilter(\"always\")\n",
    "        noisy_outputs, sensitivities = dp(data, original_output)\n",
    "        failed = any(\"Failed to generate correlated noise\" in str(msg.message) for msg in w)\n",
    "\n",
    "    result = {f'dp_t{i+1}': noisy_outputs[i] for i in range(len(noisy_outputs))}\n",
    "    result.update({f'sensitivity_t{i+1}': sensitivities[i] for i in range(len(sensitivities))})\n",
    "    return result, int(failed)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    #cov_matrix = np.array([[1.0, 0.5], [0.5, 1.0]])\n",
    "    #data = np.random.multivariate_normal([0, 0], cov_matrix, 20000).T\n",
    "    \n",
    "    cov_matrix = np.array([[1.0, 0.5, 0.3],\n",
    "                           [0.5, 1.0, 0.2],\n",
    "                           [0.3, 0.2, 1.0]])\n",
    "    data = np.random.multivariate_normal([0, 0, 0], cov_matrix, 20000).T\n",
    "    import time\n",
    "    s = time.time()\n",
    "    results = Parallel(n_jobs=20, verbose=0, batch_size=1)(\n",
    "        delayed(main)(data) for _ in range(2)\n",
    "    )\n",
    "    total_time = time.time() - s\n",
    "    print(f\"\\nTotal time taken size [3,20000]: {time.strftime('%H:%M:%S', time.gmtime(total_time))}\")\n",
    "    size =  [400,50000]\n",
    "    s = time.time()\n",
    "    data = np.random.normal(loc=0.0, scale=1.0, size=size)\n",
    "    results = Parallel(n_jobs=20, verbose=0, batch_size=1)(\n",
    "            delayed(main)(data) for _ in range(2)\n",
    "        )\n",
    "    total_time = time.time() - s\n",
    "    print(f\"\\nTotal time taken size [400,50000]: {time.strftime('%H:%M:%S', time.gmtime(total_time))}\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f5fd56-39c3-4928-a439-d51f862bbd37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38662bb8-c64d-4028-8e85-10512ab02e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c78f2bd-bfba-4c5d-802f-27974568e9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total time taken: 00:00:01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_33769/2571096367.py:49: UserWarning: Failed to generate correlated noise, using independent noise\n",
      "/tmp/ipykernel_33769/2571096367.py:49: UserWarning: Failed to generate correlated noise, using independent noise\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def main(data):\n",
    "    loo_data = [np.delete(data, i, axis=0) for i in range(data.shape[0])]\n",
    "    test = np.array(loo_data)\n",
    "    original_output = user_pipeline(data)\n",
    "    noisy_outputs, sensitivities = dp(data, original_output)\n",
    "\n",
    "    return noisy_outputs, sensitivities \n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    data = np.random.randn(40,2000000)\n",
    "    import time\n",
    "    s = time.time()\n",
    "    results = Parallel(n_jobs=20, verbose=0, batch_size=1)(\n",
    "        delayed(main)(data) for _ in range(1)\n",
    "    )\n",
    "    total_time = time.time() - s\n",
    "    print(f\"\\nTotal time taken: {time.strftime('%H:%M:%S', time.gmtime(total_time))}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7825b529-47b0-4eb3-9303-b2d0e9deb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_outputs, sensitivities  = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50556f99-094b-4f0f-b25e-d34783be0138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.07210078,  0.08122679,  0.01357883, -0.12030439]), array([0.01377031, 0.01381223, 0.0127531 , 0.01470694]))\n",
      "\n",
      "(2, 4)\n"
     ]
    }
   ],
   "source": [
    "print(noisy_outputs)\n",
    "print()\n",
    "print(np.array(noisy_outputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c654069b-b971-4899-a63f-2a63dba8db0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed044991-ac71-47e5-bb02-139d31642d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c064152c-c727-4d46-8929-37d4ea1b1b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse matrices\n",
    "# consider all subjects\n",
    "# start by eeg\n",
    "# channel neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "14446360-9d84-41fc-b16f-2a559da91416",
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = loo_(np.random.randn(48, 3465216))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc50805-b906-43bc-8da1-5bf26cb142c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "44a68d47-94c4-4be1-b3f6-06d82f1099e4",
   "metadata": {},
   "source": [
    "# image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6beb1ba-94e0-43fd-85de-ff0a10094a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, subprocess, wget, shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bdf7a719-1b48-4cf9-a12e-4eba7faafefc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [....................................................] 60545196 / 60545196\n",
      "Original file downloaded.\n"
     ]
    }
   ],
   "source": [
    "script = os.path.join(os.path.dirname(os.getcwd())+\"/CalibrateNoise/\", \"main.py\") \n",
    "file = \"input/anat/original/\"\n",
    "clean = False\n",
    "\n",
    "os.makedirs(\"img\", exist_ok=True)\n",
    "link_original = \"https://s3.amazonaws.com/openneuro.org/ds004934/sub-SAXNES2s001/func/sub-SAXNES2s001_task-DOTS_run-001_bold.nii.gz?versionId=R0fwRS9fxw8CcPZnb4zYsw9I5v19aAbP\"\n",
    "wget.download(link_original)\n",
    "os.makedirs(file, exist_ok=True)\n",
    "file_ = [os.path.join(root, file) for root, _, files in os.walk(os.getcwd()) for file in files if file.endswith(\".gz\")]\n",
    "shutil.copy2(file_[0], file)\n",
    "os.remove(file_[0])\n",
    "print(f\"\\nOriginal file downloaded.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bb201c85-bf7a-48d8-82f7-38920b976745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "\n",
      "Total time taken: 00:00:23\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = subprocess.run(\n",
    "    [\"python3\", script, file],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "print(result.stdout)\n",
    "if clean:\n",
    "    ! rm -r input\n",
    "    print(f\"Cleaning up finished\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ee85d2f0-d6ae-4052-a751-ae5536f16f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 2165760)\n",
      "(1, 2598912)\n",
      "(1, 2598912)\n",
      "(1, 3032064)\n",
      "(1, 2598912)\n",
      "(1, 3032064)\n",
      "(1, 3465216)\n",
      "(1, 2165760)\n",
      "(1, 2598912)\n",
      "(1, 2598912)\n",
      "(1, 2598912)\n",
      "(1, 2165760)\n",
      "(1, 2598912)\n",
      "(1, 3032064)\n",
      "(1, 3032064)\n",
      "(1, 2165760)\n",
      "(1, 2598912)\n",
      "(1, 2598912)\n",
      "(1, 2598912)\n",
      "(1, 3032064)\n",
      "(1, 3032064)\n",
      "(1, 3032064)\n",
      "(1, 2598912)\n",
      "(1, 3032064)\n",
      "(1, 3465216)\n",
      "(1, 2165760)\n",
      "(1, 2598912)\n",
      "(1, 2598912)\n",
      "(1, 2598912)\n",
      "(1, 2165760)\n"
     ]
    }
   ],
   "source": [
    "mne.set_log_level(\"ERROR\")\n",
    "\n",
    "BIDS_ROOT = \"/staff/vincentajoubi/wp15-chrono-T/usecase-2.4/input\"\n",
    "\n",
    "vhdr_path, channels_tsv = None, None\n",
    "for root, dirs, files in os.walk(BIDS_ROOT):\n",
    "    for f in files:\n",
    "        if f.endswith(\"_eeg.vhdr\"):\n",
    "            vhdr_path = os.path.join(root, f)\n",
    "        if f.endswith(\"_channels.tsv\"):\n",
    "            channels_tsv = os.path.join(root, f)\n",
    "    if vhdr_path and channels_tsv:\n",
    "        break\n",
    "\n",
    "raw = mne.io.read_raw_brainvision(vhdr_path, preload=True)\n",
    "\n",
    "channels_df = pd.read_csv(channels_tsv, sep=\"\\t\")\n",
    "chan_types = {row[\"name\"]: row[\"type\"].lower() for _, row in channels_df.iterrows()}\n",
    "raw.pick(channels_df[\"name\"].tolist())\n",
    "raw.set_channel_types(chan_types)\n",
    "\n",
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "raw.set_montage(montage, match_case=False)\n",
    "\n",
    "adjacency, ch_names = mne.channels.find_ch_adjacency(raw.info, ch_type=\"eeg\")\n",
    "dense = adjacency.toarray()\n",
    "\n",
    "for idx, ch in enumerate(ch_names):\n",
    "    print(np.stack([raw.get_data(picks=n) for n, flag in zip(ch_names, dense[idx]) if flag]).reshape(1, -1).shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e35e4-ceb8-4349-aa46-37f28bb9deba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8c375c-42b6-4dd1-9c0b-6a68896aa99b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b7961-45dd-4fb4-a821-7def67f4c7a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
